- Real virtuality: A Code of Ethical Conduct. Recommendations for Good Scientific Practice and the Consumers of VR-Technology
  authors::  [[Michael Madary]] [[Thomas K. Metzinger]]
  type:: [[Ethics]] 
  category:: [[Literature]]  
  published-year:: 2016
  DOI:: [10.3389/frobt.2016.00003](https://doi.org/10.3389/frobt.2016.00003) 
  citation:: Madary M and Metzinger TK (2016) Real Virtuality: A Code of Ethical Conduct. Recommendations for Good Scientific Practice and the Consumers of VR-Technology. *Front. Robot. AI* 3:3. doi: 10.3389/frobt.2016.00003
- "The goal of this article is to present a first list of ethical concerns that may arise from
  research and personal use of virtual reality (VR) and related technology, and to offer
  concrete recommendations for minimizing those risks."
- Behavior is context sensitive and the mind is plastic, which is to say that it is capable of being continuously shaped and re-shaped by a host of causal factors.
- suggest that our environment, including technology and other humans, has an unconscious influence on our behavior.
- As investigations into VR have interestingly shown, a phenomenal reality as such becomes more real – in terms of the subjective experience of presence – as more agents recognizing one and interacting with one are contained in this reality.
- VR can create a situation in which the user’s entire environment is determined by the creators of the virtual world, including “social hallucinations” induced by advanced avatar technology.
- For every self-conscious system, there exists a phenomenal unit of identification, such that the system possesses a single, conscious model of reality; the UI is a part of this model; at any given
  point in time, the UI can be characterized by a specific and determinate representational content, which in turn constitutes the system’s phenomenal self-model"
- These results can be taken together as empirical premises for an argument stating not only that there may be unexpected psychological risks if illusions of embodiment are misused, or used recklessly, but that, if we are interested in minimizing potential damage and future psychosocial costs, these risks are themselves ethically relevant.
- We, therefore, suggest that careful experiments designed with the beneficent intention of discovering the psychological impact of immersion in VR are ethically permissible.
- Standard exclusion criteria may involve, for instance, scoring above a particular threshold on scales testing for dissociative experiences (Bernstein and Putnam, 1986) or depersonalization
- For instance, once the technology is available for patients to use, who will pay for it? Should medical insurance pay for HMDs and new software?
- Some of the risks and ethical concerns that we have already encountered in the early days of the internet10 will reappear, though with the added psychological impact enabled by embodiment and a strong sense of presence.
- Once the technology is adopted for personal use, there will be no limits on the time users choose to spend immersed. Similarly, most research using VR has been conducted using adult subjects.
- There are several possible risks that can be associated with long-term immersion: addiction, manipulation of agency, unnoticed psy- chological change, mental illness, and lack of what is sometimes vaguely called “authenticity” (Metzinger and Hildt, 2011, p. 253).
- There are two relevant open questions here. First, how might the diagnostic criteria for addic- tion to VR differ from the established criteria for internet use disorder and related conditions? Note that the neurophysiological underpinnings of VR addiction may differ from that of internet use disorder (Montag and Reuter, 2015) due to the prolonged illusion of embodiment created by VR technology, and because it implies causal interaction with the low-level mechanisms con- stituting the UI. Second, can we make use of the recommended treatments for internet use disorder for the purpose of helping individuals with VR addiction?
- Importantly, the sense of agency in VR is always indirect; control of the avatar is always mediated by the technology. To be more precise, the virtual body representation has been causally coupled with and temporarily embedded into the currently active conscious self-model in the user’s brain – it is not that some mysterious “self” leaves the physical body and “enters” the avatar, but rather a novel functional configuration in which two body representations dynamically interact with each other.
- The fact that the user’s sense of agency in VR is always continuously maintained by the technology is an important one for at least two reasons. First, the technology could be used to manipulate users’ sense of agency. Second, as we discuss in the general context of mental health below, long-term immersion could cause low-level, initially unnoticeable psychological disturbances involving a loss of the sense of agency for one’s physical body.
  VR technology could manipulate users’ sense of agency by creating a false sense of agency for movements of the avatar that do not correspond to the actual body movements of the user. "
- Future experimental work can determine the conditions under which subjects will experience a sense of agency for movements of the avatar that deviate from the subject’s actual body movements (as during an OBE or in the dream state, see Kannape et al., 2010 for an empirical study). Important parameters here will likely be the timing of the false movement, the degree to which the false movement deviates from the actual position of the body, and the context of the movement within the virtual environment
- Creating a false sense of agency in VR is a clear violation of the user’s autonomy, a violation that becomes especially worri- some as users spend longer and longer periods of time immersed.
- But we do claim that creating a false sense of agency in VR is an unacceptable violation of individual autonomy when it is non-beneficent, such as when it is done out of avarice,
- Future research ought to investigate whether fac-tors such as the duration of immersion, the content of the virtual environment (including the user’s own avatar or the way in which the software controls the automatic behavior, facial gestures, or gaze of other avatars), and the user’s pre-existing psychological profile might have lasting negative effects on the mental health of users.
- Note that Depersonalization/Derealization Disorder involves feelings of unreality but not delusions of unre- ality, there is a dissociation of the low-level phenomenology of “realness” from high-level cognition.
- Depersonalization/Derealization Disorder is relevant for us here because VR technology manipulates the psychological mechanisms involved in generating experiences of “realness,” mechanisms similar or identical to those that go awry for those suffering from the disorder.
- Our concern is that long-term immersion could cause damage to the neural mechanisms that create the feeling of reality, of being in immediate contact with the world and one’s own body. Heavy users of VR may begin to experience the real world and their real bodies as unreal, effectively shifting their sense of reality exclusively to the virtual environment
- A final concern for long-term immersion stems from the fact that some may consider experiences in the virtual environment to be “inauthentic,” because those experiences are artificially generated.
- When we are not present in the flesh with others, the context and mood of a situation may be difficult to appreciate – if only because the bandwidth and the resolution of our internal models are much lower. Perhaps more importantly, there is a concern that mediating technologies will not allow us to pick up on all of the subtle bodily cues that appear to play a major role in social communication through unconscious entrainment (Frith and Frith, 2007),
- We would like to note that a likely relevant factor here may be whether those long periods of immersion involve forms of intersubjective engagement with others that are subjectively experienced as meaningful, and how this experience is integrated into our culture.
- A reasonable starting point on this issue would be to treat avatars in an analogous manner to personality rights relating to the publication of photos.
- Should we dynamically associate a “digital subject identifier” (DSI) with it [avatar]?
- Avatar ownership and individuation will be an important issue for regulatory agencies to consider. There are strong reasons to place restrictions on the way in which avatars can be used, such as protecting the interests and privacy of individuals who strongly identify with their own particu- lar avatar on social networks.
  The use of big data to “nudge” users (“Big Nudging”) combined with VR could have long-lasting effects, perhaps producing changes in users’ mental mechanisms themselves.