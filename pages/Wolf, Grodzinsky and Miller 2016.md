- Augmented Reality All Around Us: Power and Perception at a Crossroads
  authors::  [[Marty J Wolf]] [[Frances Grodzinsky]] [[Keith Miller]]
  type:: [[Ethics]] 
  category:: [[Literature]]  
  published-year:: 2016
  DOI:: [10.1145/2874239.2874257](https://doi.org/10.1145/2874239.2874257) 
  citation:: Marty J. Wolf, Frances Grodzinsky, and Keith Miller. 2016. Augmented reality all around us: power and perception at a crossroads. SIGCAS Comput. Soc. 45, 3 (September 2015), 126–131. https://doi.org/10.1145/2874239.2874257.
- These sorts of interactions raise questions regarding autonomy and suggest a strong need for informed consent protocols
- we explore how these devices impact individual identity and thus raise the question of ownership of the space between an object and someone’s eyes.
- In [7] we considered deception to be “an intentional, successful attempt by developers to deceive users, and a misapprehension by people other than the developers.”
- deceptions, in this sense, have to do with misperceptions. ... Everyone’s perception of the same object may be different because of what is virtually added.
- Regardless of whether a virtual object is a holographic image or being displayed directly onto the user’s retina, the developer takes on additional responsibility for the veracity of any information attached to the object.
- Either way, the user might misrepresent the presence or absence of the requested information, or misrepresent the information. “Yes, I can see that...” could be used as a method of establishing authority and seeking the power of information (whether the information is true or false). Rather than create an atmosphere of trust, these potentials for deception create one of distrust and uneasiness.
- First, a user who uses an AVFD to record images or audio should do so only with the consent of people included in the recording, particularly if the recording is going to be shared.
- if a developer or a user is responsible for changing another user’s virtual space, it should be clear to the affected user that this change is taking place.
- But if a developer or a user X controlled the virtual space in such a way that all watched individuals were scanned, and otherwise private information appeared in X’s virtual view, then the watched individuals should be asked for their consent, or it should not be done.
- Using such a device as a classroom tool is not necessarily ethically problematic if all students have access. However, “having access” may be more complicated than simply having a device to use; some students may not be able to benefit from an AR device. Blind students are an obvious example, but some sighted students might have adverse reactions to an AR device, including headaches or dizziness;
- Proprietary software is likely not to be readily accessible for users or for the watched; therefore, there may be interest in having at least some AVFD software be free or open source software
- If some AVFD applications require real time Internet sharing (similar to what gaming systems use for multiplayer games), again that virtual space is claimed by both developers and users.
  This sort of sharing also suggests a need for open standards."
- In cases where both developers and users may have possibly legitimate claims to ownership, we think it is vital for the participants to have explicit agreements about the ownership of the virtual space
- There are two trust relationships that must be considered: trust between users and developers; and trust between users and other individuals (some of whom may be users themselves, and other individuals who are not users). Both the developers and users must take on moral responsibility for the artifact...
- In the second trust relationship, individuals must trust that users in public are employing the device in an ethically acceptable way."
  developers of AVFDs should have as an accepted goal: examination of the effects of that artifact on society and performance of their functions with the appropriate standard of care.